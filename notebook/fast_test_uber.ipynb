{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/744 [00:00<03:14,  3.82it/s]/home/venus/fang/BayTIDE/notebook/../model_LDS.py:252: UserWarning: An output with one or more elements was resized since it had shape [1, 20, 20], which does not match the required output shape [1, 1, 20, 20]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484806139/work/aten/src/ATen/native/Resize.cpp:17.)\n",
      "  self.A = torch.matrix_exp(self.F * time_int).double()\n",
      " 10%|▉         | 74/744 [00:19<02:58,  3.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/venus/fang/BayTIDE/notebook/fast_test_uber.ipynb 单元格 1\u001b[0m in \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvenus_bridge/home/venus/fang/BayTIDE/notebook/fast_test_uber.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m flag \u001b[39m=\u001b[39m (inner_it \u001b[39m==\u001b[39m (INNER_ITER \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvenus_bridge/home/venus/fang/BayTIDE/notebook/fast_test_uber.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m model\u001b[39m.\u001b[39mmsg_approx_W(T_id)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bvenus_bridge/home/venus/fang/BayTIDE/notebook/fast_test_uber.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m model\u001b[39m.\u001b[39mpost_update_W(T_id)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvenus_bridge/home/venus/fang/BayTIDE/notebook/fast_test_uber.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m model\u001b[39m.\u001b[39mmsg_approx_U(T_id)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvenus_bridge/home/venus/fang/BayTIDE/notebook/fast_test_uber.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m model\u001b[39m.\u001b[39mfilter_update(T_id,flag)\n",
      "File \u001b[0;32m~/fang/BayTIDE/notebook/../model_BayTIDE.py:372\u001b[0m, in \u001b[0;36mBayTIDE.post_update_W\u001b[0;34m(self, T)\u001b[0m\n\u001b[1;32m    369\u001b[0m post_W_eta \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbmm(post_W_lam,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_W_m) \u001b[39m# (N,K,1)\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39m# merge the msg. factors from the llk, than tran back to mean and cov\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_W_v \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(post_W_lam \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmsg_W_lam_llk) \u001b[39m# (N,K,K)\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_W_m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbmm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_W_v, post_W_eta \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsg_W_eta_llk)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import tqdm\n",
    "import yaml\n",
    "torch.random.manual_seed(300)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils_BayOTIDE as utils\n",
    "\n",
    "from model_BayOTIDE import BayTIDE\n",
    "\n",
    "from model_LDS import LDS_GP_streaming\n",
    "\n",
    "config_path = \"./config_uber.yaml\"\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "data_file = config[\"data_path\"] # T=315 - rmse = 0.27 - Mqar23\n",
    "\n",
    "hyper_dict = utils.make_hyper_dict(config)\n",
    "\n",
    "data_dict = utils.make_data_dict(hyper_dict,data_file,fold=1)\n",
    "\n",
    "model = BayTIDE(hyper_dict,data_dict)\n",
    "\n",
    "model.reset()\n",
    "\n",
    "INNER_ITER = hyper_dict[\"INNER_ITER\"]\n",
    "EVALU_T = hyper_dict[\"EVALU_T\"]\n",
    "for epoch in range(1):\n",
    "    model.reset()\n",
    "    for T_id in tqdm.tqdm(range(model.T)):\n",
    "        model.filter_predict(T_id)\n",
    "        model.msg_llk_init()\n",
    "\n",
    "        for inner_it in range(INNER_ITER):\n",
    "\n",
    "            flag = (inner_it == (INNER_ITER - 1))\n",
    "\n",
    "            model.msg_approx_W(T_id)\n",
    "            model.post_update_W(T_id)\n",
    "\n",
    "            model.msg_approx_U(T_id)\n",
    "            model.filter_update(T_id,flag)\n",
    "\n",
    "        model.msg_approx_tau(T_id)\n",
    "        model.post_update_tau(T_id)\n",
    "\n",
    "        if T_id % EVALU_T == 0 or T_id == model.T - 1:\n",
    "            \n",
    "            # _, loss_dict = model.model_test(T_id)\n",
    "            # print(\"T_id = {}, train_rmse = {:.2f}, test_rmse= {:.2f}\".format(T_id, loss_dict[\"train_RMSE\"], loss_dict[\"test_RMSE\"]))\n",
    "            pass\n",
    "\n",
    "    model.smooth()\n",
    "    model.post_update_U_after_smooth(0)\n",
    "    _, loss_dict = model.model_test(T_id)\n",
    "    print(\"after smooth, train_rmse = {:.2f}, test_rmse= {:.2f},test_MAE= {:.2f}\".format(loss_dict[\"train_RMSE\"], loss_dict[\"test_RMSE\"],loss_dict[\"test_MAE\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
